{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d733c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336ec524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------  41.0/42.0 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 675.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.0->transformers)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "Using cached huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "Downloading regex-2024.5.15-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 92.2/269.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 174.1/269.0 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 256.0/269.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.0/269.0 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 112.6/287.9 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 174.1/287.9 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 256.0/287.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.9/287.9 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.2 MB 1.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.2 MB 1.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.2 MB 1.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.9/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.9 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 112.6/176.9 kB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 143.4/176.9 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 176.9/176.9 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.6.0 huggingface-hub-0.23.3 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb373674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.4\n",
      "  Downloading numpy-1.23.4-cp311-cp311-win_amd64.whl.metadata (2.3 kB)\n",
      "Downloading numpy-1.23.4-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.6 MB 435.7 kB/s eta 0:00:34\n",
      "   ---------------------------------------- 0.1/14.6 MB 651.6 kB/s eta 0:00:23\n",
      "    --------------------------------------- 0.2/14.6 MB 1.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.7/14.6 MB 3.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.2/14.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.7/14.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.2/14.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.7/14.6 MB 7.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.3/14.6 MB 7.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.4/14.6 MB 7.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/14.6 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.9/14.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.0/14.6 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.0/14.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.1/14.6 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.6 MB 4.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.3/14.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.4/14.6 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.7/14.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.8/14.6 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.8/14.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.0/14.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.1/14.6 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.2/14.6 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.3/14.6 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.4/14.6 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.6/14.6 MB 3.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.6/14.6 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.7/14.6 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.8/14.6 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.8/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.9/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.0/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.2/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.4/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.5/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.6/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.6/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.8/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.9/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.0/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.1/14.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.2/14.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.2/14.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.3/14.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.4/14.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.5/14.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.6/14.6 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.7/14.6 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.7/14.6 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.8/14.6 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.9/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 8.0/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.1/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.2/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 8.4/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.5/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.6/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.7/14.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 8.8/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.0/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.1/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.5/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.6/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.8/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.9/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.0/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.2/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.4/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.5/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.6/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.8/14.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.9/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.0/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.2/14.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.2/14.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.3/14.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.4/14.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.5/14.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.5/14.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.5/14.6 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.6/14.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.7/14.6 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.7/14.6 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.7/14.6 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.7/14.6 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.7/14.6 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.8/14.6 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.8/14.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.8/14.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.8/14.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.8/14.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.9/14.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.9/14.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.9/14.6 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.9/14.6 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.0/14.6 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.0/14.6 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.1/14.6 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.1/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.2/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.2/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.3/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.3/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.4/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.5/14.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.5/14.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.7/14.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.7/14.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.8/14.6 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.0/14.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.1/14.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.2/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.3/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.5/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.8/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.1/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc9204e-e649-4315-9394-b2608de4842b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a85a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_ckpt = \"indobenchmark/indobert-large-p1\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_ckpt, num_labels=8)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b110c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    B_Acc = balanced_accuracy_score(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"Balanced Accuracy\": B_Acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804691eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_text3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17160</td>\n",
       "      <td>17160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17071</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tebet eco park hasil pak anies juga gak sih ma...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>2971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  c_text3    label\n",
       "count                                               17160    17160\n",
       "unique                                              17071        8\n",
       "top     tebet eco park hasil pak anies juga gak sih ma...  Politik\n",
       "freq                                                    4     2971"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/andre/Downloads/SatriaDataScience-main/data_cleaned_aug_no-stemstop.csv\", sep=',')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31106bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c93e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_text3    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b519a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['c_text3'])\n",
    "y = list(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4391ac28-0c82-44b4-8614-1308aad84749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to index mapping: {'Demografi': 0, 'Ekonomi': 1, 'Geografi': 2, 'Ideologi': 3, 'Pertahanan dan Keamanan': 4, 'Politik': 5, 'Sosial Budaya': 6, 'Sumber Daya Alam': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded= label_encoder.fit_transform(y)\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "print(\"Label to index mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28a458a-16d7-4952-9a33-0073cbc6d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT THE DATASET\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_encoded, test_size =0.2, random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b2e405-535f-46bc-8be5-a20ceb8b5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch, padding='max_length', truncation=True, max_length=80, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe48b52-afd2-41f3-9694-c2909815437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 18006, 30359,  ...,     0,     0,     0],\n",
       "        [    2, 18006, 30359,  ...,     0,     0,     0],\n",
       "        [    2,  1369, 19145,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  2038, 15994,  ...,     0,     0,     0],\n",
       "        [    2,   596, 20425,  ...,     0,     0,     0],\n",
       "        [    2,   511,  6343,  ...,  3281,   626,     3]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings = tokenize(X_train)\n",
    "test_encodings  = tokenize(X_test)\n",
    "\n",
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd15142c-67ff-4d11-9812-3a8d04fc0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,encodings,labels):\n",
    "    self.encodings = encodings\n",
    "    self.labels = labels\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    item['labels']=torch.tensor(self.labels[idx])\n",
    "    return item\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, y_train)\n",
    "test_dataset = Dataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfe8b1-d40d-4198-bc5a-e37649cc9b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_7788\\4091585941.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\andre\\anaconda3\\envs\\test_env_gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='5148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  50/5148 00:41 < 1:14:09, 1.15 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "batch_size = 8\n",
    "\n",
    "logging_steps = len(train_dataset) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs= 3,\n",
    "    learning_rate = 1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps = 500,\n",
    "    evaluation_strategy =\"epoch\",\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=logging_steps,\n",
    "    log_level=\"error\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset= train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad980060-15ee-4679-b24f-106f325ff5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(test_dataset)\n",
    "preds_output.metrics\n",
    "y_pred=np.argmax(preds_output.predictions, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2de10-91d0-43c7-a86c-73e89a8f894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm= confusion_matrix(y_pred, y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf36085-ee8b-46f1-a3c6-c6311b02cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df_test = pd.read_csv(\"C:/Users/andre/Downloads/SatriaDataScience-main/dataset_unlabeled_penyisihan_bdc_2024.csv\", sep = \";\")\n",
    "test = list(df_test[\"Text\"])\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoded = self.tokenizer(text, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        return item\n",
    "\n",
    "# Create dataset and dataloader\n",
    "df_set = TextDataset(test, tokenizer)\n",
    "test_dataloader = DataLoader(df_test, batch_size=2)\n",
    "\n",
    "predictions = trainer.predict(test_dataloader)\n",
    "pred_labels = predictions.predictions.argmax(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9b2d5-8bf0-441c-9d3d-02e97e657188",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = {v: k for k, v in label_mapping.items()}\n",
    "string_labels = [index_to_label[label] for label in pred_labels]\n",
    "\n",
    "jawaban = pd.read_csv(\"C:/Users/andre/Downloads/SatriaDataScience-main/template_jawaban_penyisihan_bdc_2024.csv\", sep = \";\")\n",
    "jawaban[\"Kelas\"] = string_labels\n",
    "jawaban.to_csv('JawabanBDC.csv', sep=';', index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "test_env_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
